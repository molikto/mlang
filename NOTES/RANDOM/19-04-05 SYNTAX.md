## currying

in programming languages, there are three implementations for multiple argument functions:


1. direct implementation, functions can take multiple arguments
    * (most of time) allow functions taking zero arguments
        * makes less sense in a pure language
2. curring as functions returning functions
    * only has `A => B` in semantics
    * `(A, B) => C` is defined as `A => (B => C)`
3. curring as functions take tuple as parameters
    * only has `A => B` in semantics
    * `(A, B) => C` is defined as `A * B => C`


most of time 1 is not used in functional languages. currently in proof assistants, only 2 is used. 3 is used in Standard ML.


* 2 good
    * 2 enables free partial application
* 2 bad
    * 2 makes ad-hoc polymorphism harder to use. in a language with ad-hoc polymorphism, the two definition will be duplicated definition, because ad-hoc polymorphism only considers argument type
      ```
      def test(a: Int)(b: Int) = ??
      def test(a: Int) = ??
      ```
* 3 good
    * arguably 3 is more natural with pattern matching. pattern matching is defined on positive types (record, sum), so 3 makes directly implementing pattern matching in semantics level easier (a pattern matching lambda is a lambda defined on positive types). Agda translate to case tree, also Coq, Lean uses eliminator; I don't know any PA implementation of pattern matching in core language; and this will be needed if one want [overlapping patterns](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Overlapping+and+order-independent+patterns+in+type+theory&btnG=)
    * 3 makes it easier to call `funExt f g` where `f` and `g` takes multiple arguments, also `map f [(1,2,3), (4,5,6), (7, 8, 9)]`
* 3 bad
    * not easy to write partial application, we can provide one partial application *macro*, but it will make definitional equality ugly
    * it uses record type, which is not something in basic type theory (most of time only Pi and Sigma), also the syntax is messier: `(A) => B` doesn't create a record type, but `(A, B) => C` does
    
    
the problem of 2 and 3 is a problem of syntax. 

what about mixed case? it forces the definition more principle with what calling convention should be used


* `(A) => B` equals `A => B`, called with `f(a)`
* `(A, B) => C` equals `A * B => C` called with `f(a, b)`, or `val c = (a, b); f(c)`
* `(A; B) => C` equals `A => B => C` called with `f(a; b)` or `f(a)(b)` or `f(a)`
* `(A, B; C, D) => E` equals `A * B => C * D => E` called with `f(a, b; c, d)` or `f(a, b)`

------

anyway. it might be annoying to think what convention should be used to call a function, and one just want to use Agda/Haskell/Coq style currying. non-the-less Agda have pattern matching, but being able to have ad-hoc overloading (for some functions) seems a nice add-on from OO languages.
     
    
## syntax

continuing the note about currying and why Agda style curring is against pattern matching, I am thinking something called pattern tree. the view that "pattern matching should be defined on positive types" is still valid, because now with **pattern tree**, the so called "pattern matching" lambda is actually a pattern tree.


```

def case_nat: (a0 as: /a/, nat) => a = 
             _> _>      {- zero   | -> a0
                         - suc(n)
                               -  suc(suc(m))
                                         |- zero ->
                                         \- suc(m) ->
                               - suc(n) ->
                                \-zero ->
                        }
                                

```

the `/a/` syntax introduces a implicit argument

if we use this perspective, then the only problem is why record type is not encoded in sigma types? especially with record calculus. 


the only thing we can do (I think for know) is to view data types as big types

* functions etc. as basic structure
* record type
    * as a "big type" providing calculus support (what we can do is provide a !operator for single field record, or even make it default)
        * non-recursive fragment
    * also as a dependency graph, providing "out of order" matching
* inductive type as a building method of concrete types

from this we have several introduction rules and elimination rules
* introduction
    * lambda
        * pattern matching lambda
    * make
    * construct
* elimination
    * application
    * projection
  
we can give stuff that don't project, or don't project on some field a new project, also give things that don't apply a application

```
def point = record(x y: ...)
static_project point.center = point.make(0, 1)
project (x: nat) + (y: nat) = ...
```
* `point.make` gives any record type a new projection (as record is a type, it should not have a projection at all), and it is the constructor (a (maybe zero arity) function value that results in the value of that record)
* `static_project point.center` gives the value `point` (which is a type so don't project usually) a project `center`. is like static class variables in Java
* `project (x: nat) + (y: nat)` means you give any value of type `nat` a new projection `+`, and it is a function that accepts another `nat`

we can give stuff that don't apply a application, like

```
def group = record(parameter carrier: set, ...)

val nat_group = group(nat)
```


without user defined projections, we still achieve something:

* the syntax will only consists type formers, lambdas, and eliminations (application, projection, pattern matching lambda), record and inductive introduction rule is silent

 
*we can also have user defined destructors, and they will be used within pattern matching, but in this case the pattern needs to be named* (later)


with user defined projections and applications so the context will be:

* free variables
* user definitions
* user eliminations
    * user projections
        * static: static fields like Java
        * non-static: extension methods
    * user applications
        * static: record type specification
        * non-static: list index
    * user patterns
    * (more) user defined named applications
    
* order
    * application
        * if itself is a function
        * user defined static application
        * user defined non-static application
        * default ones
    * projection
        * similar

* this means when checking a term against a record/application type, you need to fail-back to user defined ones



## implicits arguments

the syntax of implicits


## implicit conversion